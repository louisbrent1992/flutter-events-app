/**
 * SerpApi Events Cron Job (EventEase)
 * 
 * Scheduled task to fetch events from Google Events via SerpApi.
 * 
 * Strategy:
 * - 250 searches / day limit (Free Tier).
 * - Schedule: Run every 20 minutes (approx 72 searches/day).
 * - Targets: Cycle through a list of key cities.
 * - Storage: Upsert into 'discoverEvents' collection.
 */

const cron = require("node-cron");
const { getFirestore } = require("firebase-admin/firestore");
const crypto = require("crypto");
const { fetchGoogleEvents } = require("./serpApi");

const db = getFirestore();

// List of cities to monitor
// Add more cities here, but ensure (24h / interval) * cities <= 250
const TARGET_CITIES = [
    "Austin, TX",
    "New York, NY",
    "Los Angeles, CA",
    "San Francisco, CA",
    "Chicago, IL",
    "Miami, FL",
    "Las Vegas, NV",
    "Nashville, TN",
    "London, UK",
];

// Helper to generate a consistent ID from a URL
function generateEventId(url) {
    return crypto.createHash('md5').update(url).digest('hex');
}

async function runSerpApiSync() {
    // Pick a random city to update
    const city = TARGET_CITIES[Math.floor(Math.random() * TARGET_CITIES.length)];
    const query = `Events in ${city}`;

    console.log(`ðŸŒ [Cron] Starting SerpApi sync for city: ${city}`);

    try {
        const events = await fetchGoogleEvents(query);
        console.log(`ðŸ“¦ [Cron] Fetched ${events.length} events from SerpApi`);

        let newCount = 0;
        let updateCount = 0;
        const batch = db.batch();
        let batchSize = 0;

        for (const event of events) {
            if (!event.sourceUrl) continue;

            // Generate a unique ID based on the source link
            const id = `google_${generateEventId(event.sourceUrl)}`;
            const docRef = db.collection("discoverEvents").doc(id);

            // Check if exists to avoid overwriting user edits if we ever allow that
            // For now, simple overwrite is fine to keep data fresh, but preserve 'createdAt'
            // We'll trust the 'updatedAt' field.

            // Note: In a real heavy production app, we'd read first or use merge.
            // set(..., { merge: true }) is good.

            batch.set(docRef, {
                ...event,
                source: "google_events",
                city: city.split(',')[0].trim(), // Ensure city matches the query context
                updatedAt: new Date().toISOString()
            }, { merge: true });

            batchSize++;

            // Firestore batches limited to 500 ops
            if (batchSize >= 400) {
                await batch.commit();
                console.log(`ðŸ’¾ [Cron] Committed batch of ${batchSize} events`);
                // Reset batch
                // batch = db.batch(); // Reassigning batch variable is tricky in loop scope without `let`
                // Simpler to just commit and break for this MVP or use a new batch.
                // Refactoring to just commit once at end if size is small (SerpApi returns ~10-20)
                // SerpApi usually returns 10-20 results per page. So one batch is fine.
            }
        }

        if (batchSize > 0) {
            await batch.commit();
            console.log(`âœ… [Cron] Successfully synced ${batchSize} events for ${city}`);
        }

    } catch (e) {
        console.error(`âŒ [Cron] Error running SerpApi sync for ${city}:`, e);
    }
}

function initSerpApiCron() {
    // Run every 20 minutes
    // cron syntax: "*/20 * * * *"
    cron.schedule("*/20 * * * *", async () => {
        await runSerpApiSync();
    });

    console.log("ðŸ“… [Cron] SerpApi Google Events sync scheduled (every 20 mins)");

    // Optional: Run once shortly after startup for dev/testing (with a delay)
    if (process.env.NODE_ENV !== 'production') {
        setTimeout(() => {
            console.log("ðŸš€ [Dev] Triggering initial SerpApi sync...");
            runSerpApiSync();
        }, 10000); // 10s delay
    }
}

module.exports = {
    initSerpApiCron,
    runSerpApiSync
};
